{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_file = 'fathers_day.mp4'\n",
    "cascade_file = 'haarcascade_frontalface_default.xml'\n",
    "result_dir = 'Result_720_1280'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(result_dir):\n",
    "    shutil.rmtree(result_dir)\n",
    "\n",
    "os.mkdir(result_dir)\n",
    "os.mkdir(os.path.join(result_dir, 'Cropped'))\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cascade_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_file)\n",
    "while not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    cv2.waitKey(1000)\n",
    "    print \"Wait for the header\"\n",
    "\n",
    "pos_frame = cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES)\n",
    "with open(os.path.join(result_dir, 'Detections.txt'), 'w') as ann:\n",
    "    while True:\n",
    "        flag, frame = cap.read()\n",
    "        if flag:\n",
    "            #convert to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray,\n",
    "                                                  scaleFactor=1.1,\n",
    "                                                  minNeighbors=5,\n",
    "                                                  minSize=(80, 80),\n",
    "                                                  flags=cv2.CASCADE_FIND_BIGGEST_OBJECT)\n",
    "            for (x, y, w, h) in faces:\n",
    "                # annotation format: frame_number bbox_h bbox_y bbox_w bbox_h\n",
    "                ann.write('%d %d %d %d %d\\n'%(pos_frame, x, y, w, h))\n",
    "                cv2.imwrite(os.path.join(result_dir, 'Cropped', '%04d.png'%(pos_frame)),frame[y:y+h, x:x+w])\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            # The frame is ready and already captured\n",
    "            cv2.imshow('video', frame)\n",
    "            pos_frame = cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES)\n",
    "            if len(faces) > 0:\n",
    "                print str(pos_frame)+\" frame. Detected face size = [%d, %d]\"%(w,h)\n",
    "            else:\n",
    "                print str(pos_frame) + \" frame.\"\n",
    "        else:\n",
    "            # The next frame is not ready, so we try to read it again\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "            print \"frame is not ready\"\n",
    "            # It is better to wait for a while for the next frame to be ready\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
